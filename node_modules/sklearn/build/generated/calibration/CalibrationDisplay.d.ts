import { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types';
/**
  Calibration curve (also known as reliability diagram) visualization.

  It is recommended to use from_estimator or from_predictions to create a CalibrationDisplay. All parameters are stored as attributes.

  Read more about calibration in the User Guide and more about the scikit-learn visualization API in Visualizations.

  @see https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibrationDisplay.html
 */
export declare class CalibrationDisplay {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: CalibrationDisplayOptions);
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Plot calibration curve using a binary classifier and data.
  
      A calibration curve, also known as a reliability diagram, uses inputs from a binary classifier and plots the average predicted probability for each bin against the fraction of positive classes, on the y-axis.
  
      Extra keyword arguments will be passed to matplotlib.pyplot.plot.
  
      Read more about calibration in the User Guide and more about the scikit-learn visualization API in Visualizations.
     */
    from_estimator(opts: CalibrationDisplayFromEstimatorOptions): Promise<any>;
    /**
      Plot calibration curve using true labels and predicted probabilities.
  
      Calibration curve, also known as reliability diagram, uses inputs from a binary classifier and plots the average predicted probability for each bin against the fraction of positive classes, on the y-axis.
  
      Extra keyword arguments will be passed to matplotlib.pyplot.plot.
  
      Read more about calibration in the User Guide and more about the scikit-learn visualization API in Visualizations.
     */
    from_predictions(opts: CalibrationDisplayFromPredictionsOptions): Promise<any>;
    /**
      Plot visualization.
  
      Extra keyword arguments will be passed to matplotlib.pyplot.plot.
     */
    plot(opts: CalibrationDisplayPlotOptions): Promise<any>;
    /**
      Calibration curve.
     */
    get line_(): Promise<any>;
    /**
      Axes with calibration curve.
     */
    get ax_(): Promise<any>;
    /**
      Figure containing the curve.
     */
    get figure_(): Promise<any>;
}
export interface CalibrationDisplayOptions {
    /**
      The proportion of samples whose class is the positive class (fraction of positives), in each bin.
     */
    prob_true?: NDArray;
    /**
      The mean predicted probability in each bin.
     */
    prob_pred?: NDArray;
    /**
      Probability estimates for the positive class, for each sample.
     */
    y_prob?: NDArray;
    /**
      Name of estimator. If None, the estimator name is not shown.
     */
    estimator_name?: string;
    /**
      The positive class when computing the calibration curve. By default, estimators.classes_[1] is considered as the positive class.
     */
    pos_label?: string | number;
}
export interface CalibrationDisplayFromEstimatorOptions {
    /**
      Fitted classifier or a fitted Pipeline in which the last estimator is a classifier. The classifier must have a predict_proba method.
     */
    estimator?: any;
    /**
      Input values.
     */
    X?: ArrayLike | SparseMatrix[];
    /**
      Binary target values.
     */
    y?: ArrayLike;
    /**
      Number of bins to discretize the [0, 1] interval into when calculating the calibration curve. A bigger number requires more data.
  
      @defaultValue `5`
     */
    n_bins?: number;
    /**
      Strategy used to define the widths of the bins.
  
      @defaultValue `'uniform'`
     */
    strategy?: 'uniform' | 'quantile';
    /**
      The positive class when computing the calibration curve. By default, estimators.classes_[1] is considered as the positive class.
     */
    pos_label?: string | number;
    /**
      Name for labeling curve. If None, the name of the estimator is used.
     */
    name?: string;
    /**
      If True, plots a reference line representing a perfectly calibrated classifier.
  
      @defaultValue `true`
     */
    ref_line?: boolean;
    /**
      Axes object to plot on. If None, a new figure and axes is created.
     */
    ax?: any;
    /**
      Keyword arguments to be passed to matplotlib.pyplot.plot.
     */
    kwargs?: any;
}
export interface CalibrationDisplayFromPredictionsOptions {
    /**
      True labels.
     */
    y_true?: ArrayLike;
    /**
      The predicted probabilities of the positive class.
     */
    y_prob?: ArrayLike;
    /**
      Number of bins to discretize the [0, 1] interval into when calculating the calibration curve. A bigger number requires more data.
  
      @defaultValue `5`
     */
    n_bins?: number;
    /**
      Strategy used to define the widths of the bins.
  
      @defaultValue `'uniform'`
     */
    strategy?: 'uniform' | 'quantile';
    /**
      The positive class when computing the calibration curve. By default, estimators.classes_[1] is considered as the positive class.
     */
    pos_label?: string | number;
    /**
      Name for labeling curve.
     */
    name?: string;
    /**
      If True, plots a reference line representing a perfectly calibrated classifier.
  
      @defaultValue `true`
     */
    ref_line?: boolean;
    /**
      Axes object to plot on. If None, a new figure and axes is created.
     */
    ax?: any;
    /**
      Keyword arguments to be passed to matplotlib.pyplot.plot.
     */
    kwargs?: any;
}
export interface CalibrationDisplayPlotOptions {
    /**
      Axes object to plot on. If None, a new figure and axes is created.
     */
    ax?: any;
    /**
      Name for labeling curve. If None, use estimator_name if not None, otherwise no labeling is shown.
     */
    name?: string;
    /**
      If True, plots a reference line representing a perfectly calibrated classifier.
  
      @defaultValue `true`
     */
    ref_line?: boolean;
    /**
      Keyword arguments to be passed to matplotlib.pyplot.plot.
     */
    kwargs?: any;
}
//# sourceMappingURL=CalibrationDisplay.d.ts.map