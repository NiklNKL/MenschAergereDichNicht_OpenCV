import { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types';
/**
  Kernel ridge regression.

  Kernel ridge regression (KRR) combines ridge regression (linear least squares with l2-norm regularization) with the kernel trick. It thus learns a linear function in the space induced by the respective kernel and the data. For non-linear kernels, this corresponds to a non-linear function in the original space.

  The form of the model learned by KRR is identical to support vector regression (SVR). However, different loss functions are used: KRR uses squared error loss while support vector regression uses epsilon-insensitive loss, both combined with l2 regularization. In contrast to SVR, fitting a KRR model can be done in closed-form and is typically faster for medium-sized datasets. On the other hand, the learned model is non-sparse and thus slower than SVR, which learns a sparse model for epsilon > 0, at prediction-time.

  This estimator has built-in support for multi-variate regression (i.e., when y is a 2d-array of shape [n_samples, n_targets]).

  @see https://scikit-learn.org/stable/modules/generated/sklearn.kernel_ridge.KernelRidge.html
 */
export declare class KernelRidge {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: KernelRidgeOptions);
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Fit Kernel Ridge regression model.
     */
    fit(opts: KernelRidgeFitOptions): Promise<any>;
    /**
      Predict using the kernel ridge model.
     */
    predict(opts: KernelRidgePredictOptions): Promise<NDArray>;
    /**
      Return the coefficient of determination of the prediction.
  
      The coefficient of determination \(R^2\) is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.
     */
    score(opts: KernelRidgeScoreOptions): Promise<number>;
    /**
      Representation of weight vector(s) in kernel space
     */
    get dual_coef_(): Promise<NDArray>;
    /**
      Training data, which is also required for prediction. If kernel == “precomputed” this is instead the precomputed training matrix, of shape (n_samples, n_samples).
     */
    get X_fit_(): Promise<NDArray | SparseMatrix[]>;
    /**
      Number of features seen during fit.
     */
    get n_features_in_(): Promise<number>;
    /**
      Names of features seen during fit. Defined only when X has feature names that are all strings.
     */
    get feature_names_in_(): Promise<NDArray>;
}
export interface KernelRidgeOptions {
    /**
      Regularization strength; must be a positive float. Regularization improves the conditioning of the problem and reduces the variance of the estimates. Larger values specify stronger regularization. Alpha corresponds to 1 / (2C) in other linear models such as LogisticRegression or LinearSVC. If an array is passed, penalties are assumed to be specific to the targets. Hence they must correspond in number. See Ridge regression and classification for formula.
  
      @defaultValue `1`
     */
    alpha?: number | ArrayLike;
    /**
      Kernel mapping used internally. This parameter is directly passed to pairwise_kernel. If kernel is a string, it must be one of the metrics in pairwise.PAIRWISE_KERNEL_FUNCTIONS or “precomputed”. If kernel is “precomputed”, X is assumed to be a kernel matrix. Alternatively, if kernel is a callable function, it is called on each pair of instances (rows) and the resulting value recorded. The callable should take two rows from X as input and return the corresponding kernel value as a single number. This means that callables from sklearn.metrics.pairwise are not allowed, as they operate on matrices, not single samples. Use the string identifying the kernel instead.
  
      @defaultValue `'linear'`
     */
    kernel?: string;
    /**
      Gamma parameter for the RBF, laplacian, polynomial, exponential chi2 and sigmoid kernels. Interpretation of the default value is left to the kernel; see the documentation for sklearn.metrics.pairwise. Ignored by other kernels.
     */
    gamma?: number;
    /**
      Degree of the polynomial kernel. Ignored by other kernels.
  
      @defaultValue `3`
     */
    degree?: number;
    /**
      Zero coefficient for polynomial and sigmoid kernels. Ignored by other kernels.
  
      @defaultValue `1`
     */
    coef0?: number;
    /**
      Additional parameters (keyword arguments) for kernel function passed as callable object.
     */
    kernel_params?: any;
}
export interface KernelRidgeFitOptions {
    /**
      Training data. If kernel == “precomputed” this is instead a precomputed kernel matrix, of shape (n_samples, n_samples).
     */
    X?: ArrayLike | SparseMatrix[];
    /**
      Target values.
     */
    y?: ArrayLike;
    /**
      Individual weights for each sample, ignored if None is passed.
     */
    sample_weight?: number | ArrayLike;
}
export interface KernelRidgePredictOptions {
    /**
      Samples. If kernel == “precomputed” this is instead a precomputed kernel matrix, shape = [n_samples, n_samples_fitted], where n_samples_fitted is the number of samples used in the fitting for this estimator.
     */
    X?: ArrayLike | SparseMatrix[];
}
export interface KernelRidgeScoreOptions {
    /**
      Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.
     */
    X?: ArrayLike[];
    /**
      True values for X.
     */
    y?: ArrayLike;
    /**
      Sample weights.
     */
    sample_weight?: ArrayLike;
}
//# sourceMappingURL=KernelRidge.d.ts.map