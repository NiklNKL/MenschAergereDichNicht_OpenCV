import { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types';
/**
  Standardize features by removing the mean and scaling to unit variance.

  The standard score of a sample x is calculated as:

  @see https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html
 */
export declare class StandardScaler {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: StandardScalerOptions);
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Compute the mean and std to be used for later scaling.
     */
    fit(opts: StandardScalerFitOptions): Promise<any>;
    /**
      Fit to data, then transform it.
  
      Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.
     */
    fit_transform(opts: StandardScalerFitTransformOptions): Promise<any[]>;
    /**
      Get output feature names for transformation.
     */
    get_feature_names_out(opts: StandardScalerGetFeatureNamesOutOptions): Promise<any>;
    /**
      Scale back the data to the original representation.
     */
    inverse_transform(opts: StandardScalerInverseTransformOptions): Promise<NDArray | SparseMatrix[]>;
    /**
      Online computation of mean and std on X for later scaling.
  
      All of X is processed as a single batch. This is intended for cases when fit is not feasible due to very large number of n_samples or because X is read from a continuous stream.
  
      The algorithm for incremental mean and std is given in Equation 1.5a,b in Chan, Tony F., Gene H. Golub, and Randall J. LeVeque. “Algorithms for computing the sample variance: Analysis and recommendations.” The American Statistician 37.3 (1983): 242-247:
     */
    partial_fit(opts: StandardScalerPartialFitOptions): Promise<any>;
    /**
      Set output container.
  
      See Introducing the set_output API for an example on how to use the API.
     */
    set_output(opts: StandardScalerSetOutputOptions): Promise<any>;
    /**
      Perform standardization by centering and scaling.
     */
    transform(opts: StandardScalerTransformOptions): Promise<NDArray | SparseMatrix[]>;
    /**
      Per feature relative scaling of the data to achieve zero mean and unit variance. Generally this is calculated using np.sqrt(var_). If a variance is zero, we can’t achieve unit variance, and the data is left as-is, giving a scaling factor of 1. scale_ is equal to None when with_std=False.
     */
    get scale_(): Promise<NDArray>;
    /**
      The mean value for each feature in the training set. Equal to None when with_mean=False.
     */
    get mean_(): Promise<NDArray>;
    /**
      The variance for each feature in the training set. Used to compute scale_. Equal to None when with_std=False.
     */
    get var_(): Promise<NDArray>;
    /**
      Number of features seen during fit.
     */
    get n_features_in_(): Promise<number>;
    /**
      Names of features seen during fit. Defined only when X has feature names that are all strings.
     */
    get feature_names_in_(): Promise<NDArray>;
    /**
      The number of samples processed by the estimator for each feature. If there are no missing samples, the n_samples_seen will be an integer, otherwise it will be an array of dtype int. If sample_weights are used it will be a float (if no missing data) or an array of dtype float that sums the weights seen so far. Will be reset on new calls to fit, but increments across partial_fit calls.
     */
    get n_samples_seen_(): Promise<number | NDArray>;
}
export interface StandardScalerOptions {
    /**
      If False, try to avoid a copy and do inplace scaling instead. This is not guaranteed to always work inplace; e.g. if the data is not a NumPy array or scipy.sparse CSR matrix, a copy may still be returned.
  
      @defaultValue `true`
     */
    copy?: boolean;
    /**
      If True, center the data before scaling. This does not work (and will raise an exception) when attempted on sparse matrices, because centering them entails building a dense matrix which in common use cases is likely to be too large to fit in memory.
  
      @defaultValue `true`
     */
    with_mean?: boolean;
    /**
      If True, scale the data to unit variance (or equivalently, unit standard deviation).
  
      @defaultValue `true`
     */
    with_std?: boolean;
}
export interface StandardScalerFitOptions {
    /**
      The data used to compute the mean and standard deviation used for later scaling along the features axis.
     */
    X?: ArrayLike | SparseMatrix[];
    /**
      Ignored.
     */
    y?: any;
    /**
      Individual weights for each sample.
     */
    sample_weight?: ArrayLike;
}
export interface StandardScalerFitTransformOptions {
    /**
      Input samples.
     */
    X?: ArrayLike[];
    /**
      Target values (None for unsupervised transformations).
     */
    y?: ArrayLike;
    /**
      Additional fit parameters.
     */
    fit_params?: any;
}
export interface StandardScalerGetFeatureNamesOutOptions {
    /**
      Input features.
     */
    input_features?: any;
}
export interface StandardScalerInverseTransformOptions {
    /**
      The data used to scale along the features axis.
     */
    X?: ArrayLike | SparseMatrix[];
    /**
      Copy the input X or not.
     */
    copy?: boolean;
}
export interface StandardScalerPartialFitOptions {
    /**
      The data used to compute the mean and standard deviation used for later scaling along the features axis.
     */
    X?: ArrayLike | SparseMatrix[];
    /**
      Ignored.
     */
    y?: any;
    /**
      Individual weights for each sample.
     */
    sample_weight?: ArrayLike;
}
export interface StandardScalerSetOutputOptions {
    /**
      Configure output of transform and fit_transform.
     */
    transform?: 'default' | 'pandas';
}
export interface StandardScalerTransformOptions {
    /**
      The data used to scale along the features axis.
     */
    X?: SparseMatrix[];
    /**
      Copy the input X or not.
     */
    copy?: boolean;
}
//# sourceMappingURL=StandardScaler.d.ts.map