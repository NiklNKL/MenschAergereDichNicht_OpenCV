import { PythonBridge, NDArray } from '@/sklearn/types';
/**
  Dot-Product kernel.

  The DotProduct kernel is non-stationary and can be obtained from linear regression by putting \(N(0, 1)\) priors on the coefficients of \(x_d (d = 1, . . . , D)\) and a prior of \(N(0, \sigma_0^2)\) on the bias. The DotProduct kernel is invariant to a rotation of the coordinates about the origin, but not translations. It is parameterized by a parameter sigma_0 \(\sigma\) which controls the inhomogenity of the kernel. For \(\sigma_0^2 =0\), the kernel is called the homogeneous linear kernel, otherwise it is inhomogeneous. The kernel is given by

  @see https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.DotProduct.html
 */
export declare class DotProduct {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: DotProductOptions);
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Return the kernel k(X, Y) and optionally its gradient.
     */
    __call__(opts: DotProductCallOptions): Promise<NDArray[]>;
    /**
      Returns a clone of self with given hyperparameters theta.
     */
    clone_with_theta(opts: DotProductCloneWithThetaOptions): Promise<any>;
    /**
      Returns the diagonal of the kernel k(X, X).
  
      The result of this method is identical to np.diag(self(X)); however, it can be evaluated more efficiently since only the diagonal is evaluated.
     */
    diag(opts: DotProductDiagOptions): Promise<NDArray>;
    /**
      Returns whether the kernel is stationary.
     */
    is_stationary(opts: DotProductIsStationaryOptions): Promise<any>;
    get hyperparameter_sigma_0(): Promise<any>;
}
export interface DotProductOptions {
    /**
      Parameter controlling the inhomogenity of the kernel. If sigma_0=0, the kernel is homogeneous.
  
      @defaultValue `1`
     */
    sigma_0?: any;
    /**
      The lower and upper bound on ‘sigma_0’. If set to “fixed”, ‘sigma_0’ cannot be changed during hyperparameter tuning.
     */
    sigma_0_bounds?: 'fixed';
}
export interface DotProductCallOptions {
    /**
      Left argument of the returned kernel k(X, Y)
     */
    X?: NDArray[];
    /**
      Right argument of the returned kernel k(X, Y). If None, k(X, X) if evaluated instead.
     */
    Y?: NDArray[];
    /**
      Determines whether the gradient with respect to the log of the kernel hyperparameter is computed. Only supported when Y is None.
  
      @defaultValue `false`
     */
    eval_gradient?: boolean;
}
export interface DotProductCloneWithThetaOptions {
    /**
      The hyperparameters
     */
    theta?: NDArray;
}
export interface DotProductDiagOptions {
    /**
      Left argument of the returned kernel k(X, Y).
     */
    X?: NDArray[];
}
export interface DotProductIsStationaryOptions {
}
//# sourceMappingURL=DotProduct.d.ts.map