import { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types';
/**
  Nu-Support Vector Classification.

  Similar to SVC but uses a parameter to control the number of support vectors.

  The implementation is based on libsvm.

  @see https://scikit-learn.org/stable/modules/generated/sklearn.svm.NuSVC.html
 */
export declare class NuSVC {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: NuSVCOptions);
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Evaluate the decision function for the samples in X.
     */
    decision_function(opts: NuSVCDecisionFunctionOptions): Promise<NDArray[]>;
    /**
      Fit the SVM model according to the given training data.
     */
    fit(opts: NuSVCFitOptions): Promise<any>;
    /**
      Perform classification on samples in X.
  
      For an one-class model, +1 or -1 is returned.
     */
    predict(opts: NuSVCPredictOptions): Promise<NDArray>;
    /**
      Compute log probabilities of possible outcomes for samples in X.
  
      The model need to have probability information computed at training time: fit with attribute probability set to True.
     */
    predict_log_proba(opts: NuSVCPredictLogProbaOptions): Promise<NDArray[]>;
    /**
      Compute probabilities of possible outcomes for samples in X.
  
      The model need to have probability information computed at training time: fit with attribute probability set to True.
     */
    predict_proba(opts: NuSVCPredictProbaOptions): Promise<NDArray[]>;
    /**
      Return the mean accuracy on the given test data and labels.
  
      In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.
     */
    score(opts: NuSVCScoreOptions): Promise<number>;
    /**
      Multipliers of parameter C of each class. Computed based on the class_weight parameter.
     */
    get class_weight_(): Promise<NDArray>;
    /**
      The unique classes labels.
     */
    get classes_(): Promise<NDArray>;
    /**
      Dual coefficients of the support vector in the decision function (see Mathematical formulation), multiplied by their targets. For multiclass, coefficient for all 1-vs-1 classifiers. The layout of the coefficients in the multiclass case is somewhat non-trivial. See the multi-class section of the User Guide for details.
     */
    get dual_coef_(): Promise<NDArray[]>;
    /**
      0 if correctly fitted, 1 if the algorithm did not converge.
     */
    get fit_status_(): Promise<number>;
    /**
      Constants in decision function.
     */
    get intercept_(): Promise<NDArray>;
    /**
      Number of features seen during fit.
     */
    get n_features_in_(): Promise<number>;
    /**
      Names of features seen during fit. Defined only when X has feature names that are all strings.
     */
    get feature_names_in_(): Promise<NDArray>;
    /**
      Number of iterations run by the optimization routine to fit the model. The shape of this attribute depends on the number of models optimized which in turn depends on the number of classes.
     */
    get n_iter_(): Promise<NDArray>;
    /**
      Indices of support vectors.
     */
    get support_(): Promise<NDArray>;
    /**
      Support vectors.
     */
    get support_vectors_(): Promise<NDArray[]>;
    /**
      Array dimensions of training vector X.
     */
    get shape_fit_(): Promise<any[]>;
}
export interface NuSVCOptions {
    /**
      An upper bound on the fraction of margin errors (see User Guide) and a lower bound of the fraction of support vectors. Should be in the interval (0, 1].
  
      @defaultValue `0.5`
     */
    nu?: number;
    /**
      Specifies the kernel type to be used in the algorithm. If none is given, ‘rbf’ will be used. If a callable is given it is used to precompute the kernel matrix.
  
      @defaultValue `'rbf'`
     */
    kernel?: 'linear' | 'poly' | 'rbf' | 'sigmoid' | 'precomputed';
    /**
      Degree of the polynomial kernel function (‘poly’). Must be non-negative. Ignored by all other kernels.
  
      @defaultValue `3`
     */
    degree?: number;
    /**
      Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’.
  
      @defaultValue `'scale'`
     */
    gamma?: 'scale' | 'auto' | number;
    /**
      Independent term in kernel function. It is only significant in ‘poly’ and ‘sigmoid’.
  
      @defaultValue `0`
     */
    coef0?: number;
    /**
      Whether to use the shrinking heuristic. See the User Guide.
  
      @defaultValue `true`
     */
    shrinking?: boolean;
    /**
      @defaultValue `false`
     */
    probability?: boolean;
    /**
      Tolerance for stopping criterion.
  
      @defaultValue `0.001`
     */
    tol?: number;
    /**
      Specify the size of the kernel cache (in MB).
  
      @defaultValue `200`
     */
    cache_size?: number;
    /**
      Set the parameter C of class i to class_weight[i]*C for SVC. If not given, all classes are supposed to have weight one. The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies as n_samples / (n_classes * np.bincount(y)).
     */
    class_weight?: any | 'balanced';
    /**
      Enable verbose output. Note that this setting takes advantage of a per-process runtime setting in libsvm that, if enabled, may not work properly in a multithreaded context.
  
      @defaultValue `false`
     */
    verbose?: boolean;
    /**
      Hard limit on iterations within solver, or -1 for no limit.
  
      @defaultValue `-1`
     */
    max_iter?: number;
    /**
      Whether to return a one-vs-rest (‘ovr’) decision function of shape (n_samples, n_classes) as all other classifiers, or the original one-vs-one (‘ovo’) decision function of libsvm which has shape (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one (‘ovo’) is always used as multi-class strategy. The parameter is ignored for binary classification.
  
      @defaultValue `'ovr'`
     */
    decision_function_shape?: 'ovo' | 'ovr';
    /**
      If true, decision_function_shape='ovr', and number of classes > 2, predict will break ties according to the confidence values of decision_function; otherwise the first class among the tied classes is returned. Please note that breaking ties comes at a relatively high computational cost compared to a simple predict.
  
      @defaultValue `false`
     */
    break_ties?: boolean;
    /**
      Controls the pseudo random number generation for shuffling the data for probability estimates. Ignored when probability is False. Pass an int for reproducible output across multiple function calls. See Glossary.
     */
    random_state?: number;
}
export interface NuSVCDecisionFunctionOptions {
    /**
      The input samples.
     */
    X?: ArrayLike[];
}
export interface NuSVCFitOptions {
    /**
      Training vectors, where n_samples is the number of samples and n_features is the number of features. For kernel=”precomputed”, the expected shape of X is (n_samples, n_samples).
     */
    X?: ArrayLike | SparseMatrix[];
    /**
      Target values (class labels in classification, real numbers in regression).
     */
    y?: ArrayLike;
    /**
      Per-sample weights. Rescale C per sample. Higher weights force the classifier to put more emphasis on these points.
     */
    sample_weight?: ArrayLike;
}
export interface NuSVCPredictOptions {
    /**
      For kernel=”precomputed”, the expected shape of X is (n_samples_test, n_samples_train).
     */
    X?: ArrayLike | SparseMatrix[];
}
export interface NuSVCPredictLogProbaOptions {
    /**
      For kernel=”precomputed”, the expected shape of X is (n_samples_test, n_samples_train).
     */
    X?: ArrayLike[];
}
export interface NuSVCPredictProbaOptions {
    /**
      For kernel=”precomputed”, the expected shape of X is (n_samples_test, n_samples_train).
     */
    X?: ArrayLike[];
}
export interface NuSVCScoreOptions {
    /**
      Test samples.
     */
    X?: ArrayLike[];
    /**
      True labels for X.
     */
    y?: ArrayLike;
    /**
      Sample weights.
     */
    sample_weight?: ArrayLike;
}
//# sourceMappingURL=NuSVC.d.ts.map