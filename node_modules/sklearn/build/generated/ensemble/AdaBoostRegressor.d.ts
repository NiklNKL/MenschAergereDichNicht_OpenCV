import { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types';
/**
  An AdaBoost regressor.

  An AdaBoost [1] regressor is a meta-estimator that begins by fitting a regressor on the original dataset and then fits additional copies of the regressor on the same dataset but where the weights of instances are adjusted according to the error of the current prediction. As such, subsequent regressors focus more on difficult cases.

  This class implements the algorithm known as AdaBoost.R2 [2].

  @see https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html
 */
export declare class AdaBoostRegressor {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: AdaBoostRegressorOptions);
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Build a boosted classifier/regressor from the training set (X, y).
     */
    fit(opts: AdaBoostRegressorFitOptions): Promise<any>;
    /**
      Predict regression value for X.
  
      The predicted regression value of an input sample is computed as the weighted median prediction of the regressors in the ensemble.
     */
    predict(opts: AdaBoostRegressorPredictOptions): Promise<NDArray>;
    /**
      Return the coefficient of determination of the prediction.
  
      The coefficient of determination \(R^2\) is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.
     */
    score(opts: AdaBoostRegressorScoreOptions): Promise<number>;
    /**
      Return staged predictions for X.
  
      The predicted regression value of an input sample is computed as the weighted median prediction of the regressors in the ensemble.
  
      This generator method yields the ensemble prediction after each iteration of boosting and therefore allows monitoring, such as to determine the prediction on a test set after each boost.
     */
    staged_predict(opts: AdaBoostRegressorStagedPredictOptions): Promise<any[]>;
    /**
      Return staged scores for X, y.
  
      This generator method yields the ensemble score after each iteration of boosting and therefore allows monitoring, such as to determine the score on a test set after each boost.
     */
    staged_score(opts: AdaBoostRegressorStagedScoreOptions): Promise<number>;
    /**
      The base estimator from which the ensemble is grown.
     */
    get estimator_(): Promise<any>;
    /**
      The collection of fitted sub-estimators.
     */
    get estimators_(): Promise<any>;
    /**
      Weights for each estimator in the boosted ensemble.
     */
    get estimator_weights_(): Promise<any>;
    /**
      Regression error for each estimator in the boosted ensemble.
     */
    get estimator_errors_(): Promise<any>;
    /**
      Number of features seen during fit.
     */
    get n_features_in_(): Promise<number>;
    /**
      Names of features seen during fit. Defined only when X has feature names that are all strings.
     */
    get feature_names_in_(): Promise<NDArray>;
}
export interface AdaBoostRegressorOptions {
    /**
      The base estimator from which the boosted ensemble is built. If None, then the base estimator is DecisionTreeRegressor initialized with max_depth=3.
     */
    estimator?: any;
    /**
      The maximum number of estimators at which boosting is terminated. In case of perfect fit, the learning procedure is stopped early. Values must be in the range [1, inf).
  
      @defaultValue `50`
     */
    n_estimators?: number;
    /**
      Weight applied to each regressor at each boosting iteration. A higher learning rate increases the contribution of each regressor. There is a trade-off between the learning_rate and n_estimators parameters. Values must be in the range (0.0, inf).
  
      @defaultValue `1`
     */
    learning_rate?: number;
    /**
      The loss function to use when updating the weights after each boosting iteration.
  
      @defaultValue `'linear'`
     */
    loss?: 'linear' | 'square' | 'exponential';
    /**
      Controls the random seed given at each estimator at each boosting iteration. Thus, it is only used when estimator exposes a random_state. In addition, it controls the bootstrap of the weights used to train the estimator at each boosting iteration. Pass an int for reproducible output across multiple function calls. See Glossary.
     */
    random_state?: number;
    /**
      The base estimator from which the boosted ensemble is built. If None, then the base estimator is DecisionTreeRegressor initialized with max_depth=3.
     */
    base_estimator?: any;
}
export interface AdaBoostRegressorFitOptions {
    /**
      The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.
     */
    X?: ArrayLike | SparseMatrix[];
    /**
      The target values.
     */
    y?: ArrayLike;
    /**
      Sample weights. If None, the sample weights are initialized to 1 / n_samples.
     */
    sample_weight?: ArrayLike;
}
export interface AdaBoostRegressorPredictOptions {
    /**
      The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.
     */
    X?: ArrayLike | SparseMatrix[];
}
export interface AdaBoostRegressorScoreOptions {
    /**
      Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.
     */
    X?: ArrayLike[];
    /**
      True values for X.
     */
    y?: ArrayLike;
    /**
      Sample weights.
     */
    sample_weight?: ArrayLike;
}
export interface AdaBoostRegressorStagedPredictOptions {
    /**
      The training input samples.
     */
    X?: ArrayLike | SparseMatrix[];
}
export interface AdaBoostRegressorStagedScoreOptions {
    /**
      The training input samples. Sparse matrix can be CSC, CSR, COO, DOK, or LIL. COO, DOK, and LIL are converted to CSR.
     */
    X?: ArrayLike | SparseMatrix[];
    /**
      Labels for X.
     */
    y?: ArrayLike;
    /**
      Sample weights.
     */
    sample_weight?: ArrayLike;
}
//# sourceMappingURL=AdaBoostRegressor.d.ts.map