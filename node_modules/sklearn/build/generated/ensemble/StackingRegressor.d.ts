import { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types';
/**
  Stack of estimators with a final regressor.

  Stacked generalization consists in stacking the output of individual estimator and use a regressor to compute the final prediction. Stacking allows to use the strength of each individual estimator by using their output as input of a final estimator.

  Note that estimators_ are fitted on the full X while final_estimator_ is trained using cross-validated predictions of the base estimators using cross_val_predict.

  @see https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html
 */
export declare class StackingRegressor {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: StackingRegressorOptions);
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Fit the estimators.
     */
    fit(opts: StackingRegressorFitOptions): Promise<any>;
    /**
      Fit the estimators and return the predictions for X for each estimator.
     */
    fit_transform(opts: StackingRegressorFitTransformOptions): Promise<NDArray[]>;
    /**
      Get output feature names for transformation.
     */
    get_feature_names_out(opts: StackingRegressorGetFeatureNamesOutOptions): Promise<any>;
    /**
      Predict target for X.
     */
    predict(opts: StackingRegressorPredictOptions): Promise<NDArray>;
    /**
      Return the coefficient of determination of the prediction.
  
      The coefficient of determination \(R^2\) is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.
     */
    score(opts: StackingRegressorScoreOptions): Promise<number>;
    /**
      Set output container.
  
      See Introducing the set_output API for an example on how to use the API.
     */
    set_output(opts: StackingRegressorSetOutputOptions): Promise<any>;
    /**
      Return the predictions for X for each estimator.
     */
    transform(opts: StackingRegressorTransformOptions): Promise<NDArray[]>;
    /**
      The elements of the estimators parameter, having been fitted on the training data. If an estimator has been set to 'drop', it will not appear in estimators_. When cv="prefit", estimators_ is set to estimators and is not fitted again.
     */
    get estimators_(): Promise<any>;
    /**
      Attribute to access any fitted sub-estimators by name.
     */
    get named_estimators_(): Promise<any>;
    /**
      Names of features seen during fit. Only defined if the underlying estimators expose such an attribute when fit.
     */
    get feature_names_in_(): Promise<NDArray>;
    /**
      The regressor to stacked the base estimators fitted.
     */
    get final_estimator_(): Promise<any>;
    /**
      The method used by each base estimator.
     */
    get stack_method_(): Promise<any>;
}
export interface StackingRegressorOptions {
    /**
      Base estimators which will be stacked together. Each element of the list is defined as a tuple of string (i.e. name) and an estimator instance. An estimator can be set to ‘drop’ using set_params.
     */
    estimators?: any;
    /**
      A regressor which will be used to combine the base estimators. The default regressor is a RidgeCV.
     */
    final_estimator?: any;
    /**
      Determines the cross-validation splitting strategy used in cross_val_predict to train final_estimator. Possible inputs for cv are:
     */
    cv?: number | 'prefit';
    /**
      The number of jobs to run in parallel for fit of all estimators. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.
     */
    n_jobs?: number;
    /**
      When False, only the predictions of estimators will be used as training data for final_estimator. When True, the final_estimator is trained on the predictions as well as the original training data.
  
      @defaultValue `false`
     */
    passthrough?: boolean;
    /**
      Verbosity level.
  
      @defaultValue `0`
     */
    verbose?: number;
}
export interface StackingRegressorFitOptions {
    /**
      Training vectors, where n_samples is the number of samples and n_features is the number of features.
     */
    X?: ArrayLike | SparseMatrix[];
    /**
      Target values.
     */
    y?: ArrayLike;
    /**
      Sample weights. If None, then samples are equally weighted. Note that this is supported only if all underlying estimators support sample weights.
     */
    sample_weight?: ArrayLike;
}
export interface StackingRegressorFitTransformOptions {
    /**
      Training vectors, where n_samples is the number of samples and n_features is the number of features.
     */
    X?: ArrayLike | SparseMatrix[];
    /**
      Target values.
     */
    y?: ArrayLike;
    /**
      Sample weights. If None, then samples are equally weighted. Note that this is supported only if all underlying estimators support sample weights.
     */
    sample_weight?: ArrayLike;
}
export interface StackingRegressorGetFeatureNamesOutOptions {
    /**
      Input features. The input feature names are only used when passthrough is True.
     */
    input_features?: any;
}
export interface StackingRegressorPredictOptions {
    /**
      Training vectors, where n_samples is the number of samples and n_features is the number of features.
     */
    X?: ArrayLike | SparseMatrix[];
    /**
      Parameters to the predict called by the final_estimator. Note that this may be used to return uncertainties from some estimators with return_std or return_cov. Be aware that it will only accounts for uncertainty in the final estimator.
     */
    predict_params?: any;
}
export interface StackingRegressorScoreOptions {
    /**
      Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.
     */
    X?: ArrayLike[];
    /**
      True values for X.
     */
    y?: ArrayLike;
    /**
      Sample weights.
     */
    sample_weight?: ArrayLike;
}
export interface StackingRegressorSetOutputOptions {
    /**
      Configure output of transform and fit_transform.
     */
    transform?: 'default' | 'pandas';
}
export interface StackingRegressorTransformOptions {
    /**
      Training vectors, where n_samples is the number of samples and n_features is the number of features.
     */
    X?: ArrayLike | SparseMatrix[];
}
//# sourceMappingURL=StackingRegressor.d.ts.map