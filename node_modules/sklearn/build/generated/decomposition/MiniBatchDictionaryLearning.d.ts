import { PythonBridge, NDArray, ArrayLike } from '@/sklearn/types';
/**
  Mini-batch dictionary learning.

  Finds a dictionary (a set of atoms) that performs well at sparsely encoding the fitted data.

  Solves the optimization problem:

  @see https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.MiniBatchDictionaryLearning.html
 */
export declare class MiniBatchDictionaryLearning {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: MiniBatchDictionaryLearningOptions);
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Fit the model from data in X.
     */
    fit(opts: MiniBatchDictionaryLearningFitOptions): Promise<any>;
    /**
      Fit to data, then transform it.
  
      Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.
     */
    fit_transform(opts: MiniBatchDictionaryLearningFitTransformOptions): Promise<any[]>;
    /**
      Get output feature names for transformation.
  
      The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].
     */
    get_feature_names_out(opts: MiniBatchDictionaryLearningGetFeatureNamesOutOptions): Promise<any>;
    /**
      Update the model using the data in X as a mini-batch.
     */
    partial_fit(opts: MiniBatchDictionaryLearningPartialFitOptions): Promise<any>;
    /**
      Set output container.
  
      See Introducing the set_output API for an example on how to use the API.
     */
    set_output(opts: MiniBatchDictionaryLearningSetOutputOptions): Promise<any>;
    /**
      Encode the data as a sparse combination of the dictionary atoms.
  
      Coding method is determined by the object parameter transform_algorithm.
     */
    transform(opts: MiniBatchDictionaryLearningTransformOptions): Promise<NDArray[]>;
    /**
      Components extracted from the data.
     */
    get components_(): Promise<NDArray[]>;
    /**
      Internal sufficient statistics that are kept by the algorithm. Keeping them is useful in online settings, to avoid losing the history of the evolution, but they shouldnâ€™t have any use for the end user. A (n_components, n_components) is the dictionary covariance matrix. B (n_features, n_components) is the data approximation matrix.
     */
    get inner_stats_(): Promise<any>;
    /**
      Number of features seen during fit.
     */
    get n_features_in_(): Promise<number>;
    /**
      Names of features seen during fit. Defined only when X has feature names that are all strings.
     */
    get feature_names_in_(): Promise<NDArray>;
    /**
      Number of iterations over the full dataset.
     */
    get n_iter_(): Promise<number>;
    /**
      The number of iteration on data batches that has been performed before.
     */
    get iter_offset_(): Promise<number>;
    /**
      RandomState instance that is generated either from a seed, the random number generattor or by np.random.
     */
    get random_state_(): Promise<any>;
    /**
      Number of mini-batches processed.
     */
    get n_steps_(): Promise<number>;
}
export interface MiniBatchDictionaryLearningOptions {
    /**
      Number of dictionary elements to extract.
     */
    n_components?: number;
    /**
      Sparsity controlling parameter.
  
      @defaultValue `1`
     */
    alpha?: number;
    /**
      Total number of iterations over data batches to perform.
  
      @defaultValue `1000`
     */
    n_iter?: number;
    /**
      Maximum number of iterations over the complete dataset before stopping independently of any early stopping criterion heuristics. If max_iter is not None, n_iter is ignored.
     */
    max_iter?: number;
    /**
      The algorithm used:
  
      @defaultValue `'lars'`
     */
    fit_algorithm?: 'lars' | 'cd';
    /**
      Number of parallel jobs to run. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.
     */
    n_jobs?: number;
    /**
      Number of samples in each mini-batch.
  
      @defaultValue `3`
     */
    batch_size?: number;
    /**
      Whether to shuffle the samples before forming batches.
  
      @defaultValue `true`
     */
    shuffle?: boolean;
    /**
      Initial value of the dictionary for warm restart scenarios.
     */
    dict_init?: NDArray[];
    /**
      Algorithm used to transform the data:
  
      @defaultValue `'omp'`
     */
    transform_algorithm?: 'lasso_lars' | 'lasso_cd' | 'lars' | 'omp' | 'threshold';
    /**
      Number of nonzero coefficients to target in each column of the solution. This is only used by algorithm='lars' and algorithm='omp'. If None, then transform_n_nonzero_coefs=int(n_features / 10).
     */
    transform_n_nonzero_coefs?: number;
    /**
      If algorithm='lasso_lars' or algorithm='lasso_cd', alpha is the penalty applied to the L1 norm. If algorithm='threshold', alpha is the absolute value of the threshold below which coefficients will be squashed to zero. If None, defaults to alpha.
     */
    transform_alpha?: number;
    /**
      To control the verbosity of the procedure.
  
      @defaultValue `false`
     */
    verbose?: boolean | number;
    /**
      Whether to split the sparse feature vector into the concatenation of its negative part and its positive part. This can improve the performance of downstream classifiers.
  
      @defaultValue `false`
     */
    split_sign?: boolean;
    /**
      Used for initializing the dictionary when dict_init is not specified, randomly shuffling the data when shuffle is set to True, and updating the dictionary. Pass an int for reproducible results across multiple function calls. See Glossary.
     */
    random_state?: number;
    /**
      Whether to enforce positivity when finding the code.
  
      @defaultValue `false`
     */
    positive_code?: boolean;
    /**
      Whether to enforce positivity when finding the dictionary.
  
      @defaultValue `false`
     */
    positive_dict?: boolean;
    /**
      Maximum number of iterations to perform if algorithm='lasso_cd' or 'lasso_lars'.
  
      @defaultValue `1000`
     */
    transform_max_iter?: number;
    /**
      A callable that gets invoked at the end of each iteration.
     */
    callback?: any;
    /**
      Control early stopping based on the norm of the differences in the dictionary between 2 steps. Used only if max_iter is not None.
  
      To disable early stopping based on changes in the dictionary, set tol to 0.0.
  
      @defaultValue `0.001`
     */
    tol?: number;
    /**
      Control early stopping based on the consecutive number of mini batches that does not yield an improvement on the smoothed cost function. Used only if max_iter is not None.
  
      To disable convergence detection based on cost function, set max_no_improvement to None.
  
      @defaultValue `10`
     */
    max_no_improvement?: number;
}
export interface MiniBatchDictionaryLearningFitOptions {
    /**
      Training vector, where n_samples is the number of samples and n_features is the number of features.
     */
    X?: ArrayLike[];
    /**
      Not used, present for API consistency by convention.
     */
    y?: any;
}
export interface MiniBatchDictionaryLearningFitTransformOptions {
    /**
      Input samples.
     */
    X?: ArrayLike[];
    /**
      Target values (None for unsupervised transformations).
     */
    y?: ArrayLike;
    /**
      Additional fit parameters.
     */
    fit_params?: any;
}
export interface MiniBatchDictionaryLearningGetFeatureNamesOutOptions {
    /**
      Only used to validate feature names with the names seen in fit.
     */
    input_features?: any;
}
export interface MiniBatchDictionaryLearningPartialFitOptions {
    /**
      Training vector, where n_samples is the number of samples and n_features is the number of features.
     */
    X?: ArrayLike[];
    /**
      Not used, present for API consistency by convention.
     */
    y?: any;
    /**
      The number of iteration on data batches that has been performed before this call to partial_fit. This is optional: if no number is passed, the memory of the object is used.
     */
    iter_offset?: number;
}
export interface MiniBatchDictionaryLearningSetOutputOptions {
    /**
      Configure output of transform and fit_transform.
     */
    transform?: 'default' | 'pandas';
}
export interface MiniBatchDictionaryLearningTransformOptions {
    /**
      Test data to be transformed, must have the same number of features as the data used to train the model.
     */
    X?: NDArray[];
}
//# sourceMappingURL=MiniBatchDictionaryLearning.d.ts.map