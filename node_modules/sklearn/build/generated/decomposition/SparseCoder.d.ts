import { PythonBridge, NDArray, ArrayLike } from '@/sklearn/types';
/**
  Sparse coding.

  Finds a sparse representation of data against a fixed, precomputed dictionary.

  Each row of the result is the solution to a sparse coding problem. The goal is to find a sparse array code such that:

  @see https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.SparseCoder.html
 */
export declare class SparseCoder {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: SparseCoderOptions);
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Do nothing and return the estimator unchanged.
  
      This method is just there to implement the usual API and hence work in pipelines.
     */
    fit(opts: SparseCoderFitOptions): Promise<any>;
    /**
      Fit to data, then transform it.
  
      Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.
     */
    fit_transform(opts: SparseCoderFitTransformOptions): Promise<any[]>;
    /**
      Get output feature names for transformation.
  
      The feature names out will prefixed by the lowercased class name. For example, if the transformer outputs 3 features, then the feature names out are: ["class_name0", "class_name1", "class_name2"].
     */
    get_feature_names_out(opts: SparseCoderGetFeatureNamesOutOptions): Promise<any>;
    /**
      Set output container.
  
      See Introducing the set_output API for an example on how to use the API.
     */
    set_output(opts: SparseCoderSetOutputOptions): Promise<any>;
    /**
      Encode the data as a sparse combination of the dictionary atoms.
  
      Coding method is determined by the object parameter transform_algorithm.
     */
    transform(opts: SparseCoderTransformOptions): Promise<NDArray[]>;
    /**
      Names of features seen during fit. Defined only when X has feature names that are all strings.
     */
    get feature_names_in_(): Promise<NDArray>;
}
export interface SparseCoderOptions {
    /**
      The dictionary atoms used for sparse coding. Lines are assumed to be normalized to unit norm.
     */
    dictionary?: NDArray[];
    /**
      Algorithm used to transform the data:
  
      @defaultValue `'omp'`
     */
    transform_algorithm?: 'lasso_lars' | 'lasso_cd' | 'lars' | 'omp' | 'threshold';
    /**
      Number of nonzero coefficients to target in each column of the solution. This is only used by algorithm='lars' and algorithm='omp' and is overridden by alpha in the omp case. If None, then transform_n_nonzero_coefs=int(n_features / 10).
     */
    transform_n_nonzero_coefs?: number;
    /**
      If algorithm='lasso_lars' or algorithm='lasso_cd', alpha is the penalty applied to the L1 norm. If algorithm='threshold', alpha is the absolute value of the threshold below which coefficients will be squashed to zero. If algorithm='omp', alpha is the tolerance parameter: the value of the reconstruction error targeted. In this case, it overrides n_nonzero_coefs. If None, default to 1.
     */
    transform_alpha?: number;
    /**
      Whether to split the sparse feature vector into the concatenation of its negative part and its positive part. This can improve the performance of downstream classifiers.
  
      @defaultValue `false`
     */
    split_sign?: boolean;
    /**
      Number of parallel jobs to run. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.
     */
    n_jobs?: number;
    /**
      Whether to enforce positivity when finding the code.
  
      @defaultValue `false`
     */
    positive_code?: boolean;
    /**
      Maximum number of iterations to perform if algorithm='lasso_cd' or lasso_lars.
  
      @defaultValue `1000`
     */
    transform_max_iter?: number;
}
export interface SparseCoderFitOptions {
    /**
      Not used, present for API consistency by convention.
     */
    X?: any;
    /**
      Not used, present for API consistency by convention.
     */
    y?: any;
}
export interface SparseCoderFitTransformOptions {
    /**
      Input samples.
     */
    X?: ArrayLike[];
    /**
      Target values (None for unsupervised transformations).
     */
    y?: ArrayLike;
    /**
      Additional fit parameters.
     */
    fit_params?: any;
}
export interface SparseCoderGetFeatureNamesOutOptions {
    /**
      Only used to validate feature names with the names seen in fit.
     */
    input_features?: any;
}
export interface SparseCoderSetOutputOptions {
    /**
      Configure output of transform and fit_transform.
     */
    transform?: 'default' | 'pandas';
}
export interface SparseCoderTransformOptions {
    /**
      Training vector, where n_samples is the number of samples and n_features is the number of features.
     */
    X?: NDArray[];
    /**
      Not used, present for API consistency by convention.
     */
    y?: any;
}
//# sourceMappingURL=SparseCoder.d.ts.map