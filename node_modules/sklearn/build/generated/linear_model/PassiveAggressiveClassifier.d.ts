import { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types';
/**
  Passive Aggressive Classifier.

  @see https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.PassiveAggressiveClassifier.html
 */
export declare class PassiveAggressiveClassifier {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: PassiveAggressiveClassifierOptions);
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Predict confidence scores for samples.
  
      The confidence score for a sample is proportional to the signed distance of that sample to the hyperplane.
     */
    decision_function(opts: PassiveAggressiveClassifierDecisionFunctionOptions): Promise<NDArray>;
    /**
      Convert coefficient matrix to dense array format.
  
      Converts the coef_ member (back) to a numpy.ndarray. This is the default format of coef_ and is required for fitting, so calling this method is only required on models that have previously been sparsified; otherwise, it is a no-op.
     */
    densify(opts: PassiveAggressiveClassifierDensifyOptions): Promise<any>;
    /**
      Fit linear model with Passive Aggressive algorithm.
     */
    fit(opts: PassiveAggressiveClassifierFitOptions): Promise<any>;
    /**
      Fit linear model with Passive Aggressive algorithm.
     */
    partial_fit(opts: PassiveAggressiveClassifierPartialFitOptions): Promise<any>;
    /**
      Predict class labels for samples in X.
     */
    predict(opts: PassiveAggressiveClassifierPredictOptions): Promise<NDArray>;
    /**
      Return the mean accuracy on the given test data and labels.
  
      In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.
     */
    score(opts: PassiveAggressiveClassifierScoreOptions): Promise<number>;
    /**
      Convert coefficient matrix to sparse format.
  
      Converts the coef_ member to a scipy.sparse matrix, which for L1-regularized models can be much more memory- and storage-efficient than the usual numpy.ndarray representation.
  
      The intercept_ member is not converted.
     */
    sparsify(opts: PassiveAggressiveClassifierSparsifyOptions): Promise<any>;
    /**
      Weights assigned to the features.
     */
    get coef_(): Promise<NDArray[][]>;
    /**
      Constants in decision function.
     */
    get intercept_(): Promise<NDArray[]>;
    /**
      Number of features seen during fit.
     */
    get n_features_in_(): Promise<number>;
    /**
      Names of features seen during fit. Defined only when X has feature names that are all strings.
     */
    get feature_names_in_(): Promise<NDArray>;
    /**
      The actual number of iterations to reach the stopping criterion. For multiclass fits, it is the maximum over every binary fit.
     */
    get n_iter_(): Promise<number>;
    /**
      The unique classes labels.
     */
    get classes_(): Promise<NDArray>;
    /**
      Number of weight updates performed during training. Same as (n_iter_ * n_samples + 1).
     */
    get t_(): Promise<number>;
    /**
      Loss function used by the algorithm.
     */
    get loss_function_(): Promise<any>;
}
export interface PassiveAggressiveClassifierOptions {
    /**
      Maximum step size (regularization). Defaults to 1.0.
  
      @defaultValue `1`
     */
    C?: number;
    /**
      Whether the intercept should be estimated or not. If False, the data is assumed to be already centered.
  
      @defaultValue `true`
     */
    fit_intercept?: boolean;
    /**
      The maximum number of passes over the training data (aka epochs). It only impacts the behavior in the fit method, and not the partial_fit method.
  
      @defaultValue `1000`
     */
    max_iter?: number;
    /**
      The stopping criterion. If it is not None, the iterations will stop when (loss > previous_loss - tol).
  
      @defaultValue `0.001`
     */
    tol?: number;
    /**
      Whether to use early stopping to terminate training when validation. score is not improving. If set to True, it will automatically set aside a stratified fraction of training data as validation and terminate training when validation score is not improving by at least tol for n_iter_no_change consecutive epochs.
  
      @defaultValue `false`
     */
    early_stopping?: boolean;
    /**
      The proportion of training data to set aside as validation set for early stopping. Must be between 0 and 1. Only used if early_stopping is True.
  
      @defaultValue `0.1`
     */
    validation_fraction?: number;
    /**
      Number of iterations with no improvement to wait before early stopping.
  
      @defaultValue `5`
     */
    n_iter_no_change?: number;
    /**
      Whether or not the training data should be shuffled after each epoch.
  
      @defaultValue `true`
     */
    shuffle?: boolean;
    /**
      The verbosity level.
  
      @defaultValue `0`
     */
    verbose?: number;
    /**
      The loss function to be used: hinge: equivalent to PA-I in the reference paper. squared_hinge: equivalent to PA-II in the reference paper.
  
      @defaultValue `'hinge'`
     */
    loss?: string;
    /**
      The number of CPUs to use to do the OVA (One Versus All, for multi-class problems) computation. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.
     */
    n_jobs?: number;
    /**
      Used to shuffle the training data, when shuffle is set to True. Pass an int for reproducible output across multiple function calls. See Glossary.
     */
    random_state?: number;
    /**
      When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See the Glossary.
  
      Repeatedly calling fit or partial_fit when warm_start is True can result in a different solution than when calling fit a single time because of the way the data is shuffled.
  
      @defaultValue `false`
     */
    warm_start?: boolean;
    /**
      Preset for the class_weight fit parameter.
  
      Weights associated with classes. If not given, all classes are supposed to have weight one.
  
      The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y)).
     */
    class_weight?: any | 'balanced';
    /**
      When set to True, computes the averaged SGD weights and stores the result in the coef_ attribute. If set to an int greater than 1, averaging will begin once the total number of samples seen reaches average. So average=10 will begin averaging after seeing 10 samples.
  
      @defaultValue `false`
     */
    average?: boolean | number;
}
export interface PassiveAggressiveClassifierDecisionFunctionOptions {
    /**
      The data matrix for which we want to get the confidence scores.
     */
    X?: ArrayLike | SparseMatrix[];
}
export interface PassiveAggressiveClassifierDensifyOptions {
}
export interface PassiveAggressiveClassifierFitOptions {
    /**
      Training data.
     */
    X?: ArrayLike | SparseMatrix[];
    /**
      Target values.
     */
    y?: ArrayLike;
    /**
      The initial coefficients to warm-start the optimization.
     */
    coef_init?: NDArray[];
    /**
      The initial intercept to warm-start the optimization.
     */
    intercept_init?: NDArray;
}
export interface PassiveAggressiveClassifierPartialFitOptions {
    /**
      Subset of the training data.
     */
    X?: ArrayLike | SparseMatrix[];
    /**
      Subset of the target values.
     */
    y?: ArrayLike;
    /**
      Classes across all calls to partial_fit. Can be obtained by via np.unique(y_all), where y_all is the target vector of the entire dataset. This argument is required for the first call to partial_fit and can be omitted in the subsequent calls. Note that y doesn’t need to contain all labels in classes.
     */
    classes?: NDArray;
}
export interface PassiveAggressiveClassifierPredictOptions {
    /**
      The data matrix for which we want to get the predictions.
     */
    X?: ArrayLike | SparseMatrix[];
}
export interface PassiveAggressiveClassifierScoreOptions {
    /**
      Test samples.
     */
    X?: ArrayLike[];
    /**
      True labels for X.
     */
    y?: ArrayLike;
    /**
      Sample weights.
     */
    sample_weight?: ArrayLike;
}
export interface PassiveAggressiveClassifierSparsifyOptions {
}
//# sourceMappingURL=PassiveAggressiveClassifier.d.ts.map