import { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types';
/**
  Lasso linear model with iterative fitting along a regularization path.

  See glossary entry for cross-validation estimator.

  The best model is selected by cross-validation.

  The optimization objective for Lasso is:

  @see https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html
 */
export declare class LassoCV {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: LassoCVOptions);
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Fit linear model with coordinate descent.
  
      Fit is on grid of alphas and best alpha estimated by cross-validation.
     */
    fit(opts: LassoCVFitOptions): Promise<any>;
    /**
      Compute Lasso path with coordinate descent.
  
      The Lasso optimization function varies for mono and multi-outputs.
  
      For mono-output tasks it is:
     */
    path(opts: LassoCVPathOptions): Promise<NDArray>;
    /**
      Predict using the linear model.
     */
    predict(opts: LassoCVPredictOptions): Promise<any>;
    /**
      Return the coefficient of determination of the prediction.
  
      The coefficient of determination \(R^2\) is defined as \((1 - \frac{u}{v})\), where \(u\) is the residual sum of squares ((y_true - y_pred)** 2).sum() and \(v\) is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a \(R^2\) score of 0.0.
     */
    score(opts: LassoCVScoreOptions): Promise<number>;
    /**
      The amount of penalization chosen by cross validation.
     */
    get alpha_(): Promise<number>;
    /**
      Parameter vector (w in the cost function formula).
     */
    get coef_(): Promise<NDArray>;
    /**
      Independent term in decision function.
     */
    get intercept_(): Promise<number | NDArray>;
    /**
      Mean square error for the test set on each fold, varying alpha.
     */
    get mse_path_(): Promise<NDArray[]>;
    /**
      The grid of alphas used for fitting.
     */
    get alphas_(): Promise<NDArray>;
    /**
      The dual gap at the end of the optimization for the optimal alpha (alpha_).
     */
    get dual_gap_(): Promise<number | NDArray>;
    /**
      Number of iterations run by the coordinate descent solver to reach the specified tolerance for the optimal alpha.
     */
    get n_iter_(): Promise<number>;
    /**
      Number of features seen during fit.
     */
    get n_features_in_(): Promise<number>;
    /**
      Names of features seen during fit. Defined only when X has feature names that are all strings.
     */
    get feature_names_in_(): Promise<NDArray>;
}
export interface LassoCVOptions {
    /**
      Length of the path. eps=1e-3 means that alpha_min / alpha_max = 1e-3.
  
      @defaultValue `0.001`
     */
    eps?: number;
    /**
      Number of alphas along the regularization path.
  
      @defaultValue `100`
     */
    n_alphas?: number;
    /**
      List of alphas where to compute the models. If None alphas are set automatically.
     */
    alphas?: ArrayLike;
    /**
      Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be centered).
  
      @defaultValue `true`
     */
    fit_intercept?: boolean;
    /**
      Whether to use a precomputed Gram matrix to speed up calculations. If set to 'auto' let us decide. The Gram matrix can also be passed as argument.
  
      @defaultValue `'auto'`
     */
    precompute?: 'auto' | boolean | ArrayLike[];
    /**
      The maximum number of iterations.
  
      @defaultValue `1000`
     */
    max_iter?: number;
    /**
      The tolerance for the optimization: if the updates are smaller than tol, the optimization code checks the dual gap for optimality and continues until it is smaller than tol.
  
      @defaultValue `0.0001`
     */
    tol?: number;
    /**
      If True, X will be copied; else, it may be overwritten.
  
      @defaultValue `true`
     */
    copy_X?: boolean;
    /**
      Determines the cross-validation splitting strategy. Possible inputs for cv are:
     */
    cv?: number;
    /**
      Amount of verbosity.
  
      @defaultValue `false`
     */
    verbose?: boolean | number;
    /**
      Number of CPUs to use during the cross validation. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.
     */
    n_jobs?: number;
    /**
      If positive, restrict regression coefficients to be positive.
  
      @defaultValue `false`
     */
    positive?: boolean;
    /**
      The seed of the pseudo random number generator that selects a random feature to update. Used when selection == ‘random’. Pass an int for reproducible output across multiple function calls. See Glossary.
     */
    random_state?: number;
    /**
      If set to ‘random’, a random coefficient is updated every iteration rather than looping over features sequentially by default. This (setting to ‘random’) often leads to significantly faster convergence especially when tol is higher than 1e-4.
  
      @defaultValue `'cyclic'`
     */
    selection?: 'cyclic' | 'random';
}
export interface LassoCVFitOptions {
    /**
      Training data. Pass directly as Fortran-contiguous data to avoid unnecessary memory duplication. If y is mono-output, X can be sparse.
     */
    X?: ArrayLike | SparseMatrix[];
    /**
      Target values.
     */
    y?: ArrayLike;
    /**
      Sample weights used for fitting and evaluation of the weighted mean squared error of each cv-fold. Note that the cross validated MSE that is finally used to find the best model is the unweighted mean over the (weighted) MSEs of each test fold.
     */
    sample_weight?: number | ArrayLike;
}
export interface LassoCVPathOptions {
    /**
      Training data. Pass directly as Fortran-contiguous data to avoid unnecessary memory duplication. If y is mono-output then X can be sparse.
     */
    X?: ArrayLike | SparseMatrix[];
    /**
      Target values.
     */
    y?: ArrayLike | SparseMatrix;
    /**
      Length of the path. eps=1e-3 means that alpha_min / alpha_max = 1e-3.
  
      @defaultValue `0.001`
     */
    eps?: number;
    /**
      Number of alphas along the regularization path.
  
      @defaultValue `100`
     */
    n_alphas?: number;
    /**
      List of alphas where to compute the models. If None alphas are set automatically.
     */
    alphas?: NDArray;
    /**
      Whether to use a precomputed Gram matrix to speed up calculations. If set to 'auto' let us decide. The Gram matrix can also be passed as argument.
  
      @defaultValue `'auto'`
     */
    precompute?: 'auto' | boolean | ArrayLike[];
    /**
      Xy = np.dot(X.T, y) that can be precomputed. It is useful only when the Gram matrix is precomputed.
     */
    Xy?: ArrayLike;
    /**
      If True, X will be copied; else, it may be overwritten.
  
      @defaultValue `true`
     */
    copy_X?: boolean;
    /**
      The initial values of the coefficients.
     */
    coef_init?: NDArray;
    /**
      Amount of verbosity.
  
      @defaultValue `false`
     */
    verbose?: boolean | number;
    /**
      Whether to return the number of iterations or not.
  
      @defaultValue `false`
     */
    return_n_iter?: boolean;
    /**
      If set to True, forces coefficients to be positive. (Only allowed when y.ndim == 1).
  
      @defaultValue `false`
     */
    positive?: boolean;
    /**
      Keyword arguments passed to the coordinate descent solver.
     */
    params?: any;
}
export interface LassoCVPredictOptions {
    /**
      Samples.
     */
    X?: ArrayLike | SparseMatrix;
}
export interface LassoCVScoreOptions {
    /**
      Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape (n_samples, n_samples_fitted), where n_samples_fitted is the number of samples used in the fitting for the estimator.
     */
    X?: ArrayLike[];
    /**
      True values for X.
     */
    y?: ArrayLike;
    /**
      Sample weights.
     */
    sample_weight?: ArrayLike;
}
//# sourceMappingURL=LassoCV.d.ts.map