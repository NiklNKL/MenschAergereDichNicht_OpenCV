import { PythonBridge, NDArray, ArrayLike, SparseMatrix } from '@/sklearn/types';
/**
  Ridge classifier with built-in cross-validation.

  See glossary entry for cross-validation estimator.

  By default, it performs Leave-One-Out Cross-Validation. Currently, only the n_features > n_samples case is handled efficiently.

  @see https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifierCV.html
 */
export declare class RidgeClassifierCV {
    id: string;
    opts: any;
    _py: PythonBridge;
    _isInitialized: boolean;
    _isDisposed: boolean;
    constructor(opts?: RidgeClassifierCVOptions);
    get py(): PythonBridge;
    set py(pythonBridge: PythonBridge);
    /**
      Initializes the underlying Python resources.
  
      This instance is not usable until the `Promise` returned by `init()` resolves.
     */
    init(py: PythonBridge): Promise<void>;
    /**
      Disposes of the underlying Python resources.
  
      Once `dispose()` is called, the instance is no longer usable.
     */
    dispose(): Promise<void>;
    /**
      Predict confidence scores for samples.
  
      The confidence score for a sample is proportional to the signed distance of that sample to the hyperplane.
     */
    decision_function(opts: RidgeClassifierCVDecisionFunctionOptions): Promise<NDArray>;
    /**
      Fit Ridge classifier with cv.
     */
    fit(opts: RidgeClassifierCVFitOptions): Promise<any>;
    /**
      Predict class labels for samples in X.
     */
    predict(opts: RidgeClassifierCVPredictOptions): Promise<NDArray>;
    /**
      Return the mean accuracy on the given test data and labels.
  
      In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.
     */
    score(opts: RidgeClassifierCVScoreOptions): Promise<number>;
    /**
      Cross-validation values for each alpha (only if store_cv_values=True and cv=None). After fit() has been called, this attribute will contain the mean squared errors if scoring is None otherwise it will contain standardized per point prediction values.
     */
    get cv_values_(): Promise<NDArray[][]>;
    /**
      Coefficient of the features in the decision function.
  
      coef_ is of shape (1, n_features) when the given problem is binary.
     */
    get coef_(): Promise<NDArray[]>;
    /**
      Independent term in decision function. Set to 0.0 if fit_intercept = False.
     */
    get intercept_(): Promise<number | NDArray>;
    /**
      Estimated regularization parameter.
     */
    get alpha_(): Promise<number>;
    /**
      Score of base estimator with best alpha.
     */
    get best_score_(): Promise<number>;
    /**
      Number of features seen during fit.
     */
    get n_features_in_(): Promise<number>;
    /**
      Names of features seen during fit. Defined only when X has feature names that are all strings.
     */
    get feature_names_in_(): Promise<NDArray>;
}
export interface RidgeClassifierCVOptions {
    /**
      Array of alpha values to try. Regularization strength; must be a positive float. Regularization improves the conditioning of the problem and reduces the variance of the estimates. Larger values specify stronger regularization. Alpha corresponds to 1 / (2C) in other linear models such as LogisticRegression or LinearSVC.
     */
    alphas?: ArrayLike;
    /**
      Whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be centered).
  
      @defaultValue `true`
     */
    fit_intercept?: boolean;
    /**
      A string (see model evaluation documentation) or a scorer callable object / function with signature scorer(estimator, X, y).
     */
    scoring?: string;
    /**
      Determines the cross-validation splitting strategy. Possible inputs for cv are:
     */
    cv?: number;
    /**
      Weights associated with classes in the form {class_label: weight}. If not given, all classes are supposed to have weight one.
  
      The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y)).
     */
    class_weight?: any | 'balanced';
    /**
      Flag indicating if the cross-validation values corresponding to each alpha should be stored in the cv_values_ attribute (see below). This flag is only compatible with cv=None (i.e. using Leave-One-Out Cross-Validation).
  
      @defaultValue `false`
     */
    store_cv_values?: boolean;
}
export interface RidgeClassifierCVDecisionFunctionOptions {
    /**
      The data matrix for which we want to get the confidence scores.
     */
    X?: ArrayLike | SparseMatrix[];
}
export interface RidgeClassifierCVFitOptions {
    /**
      Training vectors, where n_samples is the number of samples and n_features is the number of features. When using GCV, will be cast to float64 if necessary.
     */
    X?: NDArray[];
    /**
      Target values. Will be cast to X’s dtype if necessary.
     */
    y?: NDArray;
    /**
      Individual weights for each sample. If given a float, every sample will have the same weight.
     */
    sample_weight?: number | NDArray;
}
export interface RidgeClassifierCVPredictOptions {
    /**
      The data matrix for which we want to predict the targets.
     */
    X?: ArrayLike[];
}
export interface RidgeClassifierCVScoreOptions {
    /**
      Test samples.
     */
    X?: ArrayLike[];
    /**
      True labels for X.
     */
    y?: ArrayLike;
    /**
      Sample weights.
     */
    sample_weight?: ArrayLike;
}
//# sourceMappingURL=RidgeClassifierCV.d.ts.map